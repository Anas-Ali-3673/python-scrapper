This project is a web scraper designed to download and save NeurIPS conference papers along with their metadata. The scraper uses a GUI built with CustomTkinter to allow users to specify the year range for the papers they want to download.

## Features

- Fetches paper links from the NeurIPS website for a specified year range.
- Downloads paper PDFs and saves them to a specified directory.
- Extracts and saves metadata (title, authors, URL, PDF path) to a CSV file.
- Displays a progress bar and log area to track the scraping process.
- Uses multithreading to speed up the download process.

## Requirements

- Python 3.x
- Required Python packages:
  - `requests`
  - `beautifulsoup4`
  - `customtkinter`
  - `tkinter`

You can install the required packages using the following command:

```sh
pip install requests beautifulsoup4 customtkinter
```

## Usage

1. Clone the repository or download the source code.
2. Navigate to the project directory.
3. Run the scrapper.py script:

```sh
python scrapper.py
```

4. The GUI will open. Enter the start and end year for the papers you want to download.
5. Click the "Start Scraping" button to begin the scraping process.

## Screenshots

![Scraper GUI](./WhatsApp%20Image%202025-02-16%20at%209.47.40%20PM.jpeg)
![Scraper GUI](./WhatsApp%20Image%202025-02-16%20at%209.58.12%20PM.jpeg)

## Code Overview

### Constants

- `BASE_URL`: Base URL for the NeurIPS paper abstracts.
- `OUTPUT_DIR`: Directory to save the downloaded PDFs.
- `METADATA_FILE`: Path to the CSV file for saving metadata.
- `THREAD_COUNT`: Number of threads to use for downloading PDFs.

### Functions

- `get_paper_links(year)`: Extracts paper abstract links for a given year.
- `fetch_metadata(paper_url)`: Fetches metadata (title, authors) from the paper abstract page.
- `download_pdf(paper_url, metadata)`: Downloads a paper PDF and saves its metadata.
- `start_scraping()`: Main function to scrape and download PDFs with metadata.
- `scrape_papers(start_year, end_year)`: Scrapes papers in the given year range.
- `update_progress()`: Updates the progress bar and log area.

### CustomTkinter UI Setup

- The GUI is built using CustomTkinter.
- Users can input the start and end year for the papers they want to download.
- A progress bar and log area are provided to track the scraping process.

## License

This project is licensed under the MIT License. See the LICENSE file for details.

## Acknowledgements

- [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) for web scraping.
- [CustomTkinter](https://github.com/TomSchimansky/CustomTkinter) for the GUI.
- [NeurIPS](https://neurips.cc/) for providing the paper abstracts and PDFs.

Feel free to contribute to this project by submitting issues or pull requests. Happy scraping!

# NeurIPS Paper Annotator

This script annotates the scraped NeurIPS papers using the Hugging Face API and saves the results in JSON format. The script classifies each paper into one of the predefined categories based on its title and abstract.

## Features

- Reads metadata from a CSV file containing scraped NeurIPS papers.
- Uses Hugging Face's zero-shot classification model to classify papers into predefined categories.
- Saves the annotated papers in JSON format.

## Requirements

- Python 3.x
- Required Python packages:
  - `requests`
  - `csv`
  - `json`

You can install the required packages using the following command:

```sh
pip install requests
```

## Usage

1. Clone the repository or download the source code.
2. Ensure you have the `metadata.csv` file generated by the scraper in the specified directory.
3. Replace the `HF_API_KEY` constant with your Hugging Face API key.
4. Run the annotate_papers.py script:

```sh
python annotate_papers.py
```

## Code Overview

### Constants

- `INPUT_CSV`: Path to the CSV file containing the scraped dataset.
- `OUTPUT_JSON`: Path to save the annotated dataset in JSON format.
- `HF_API_KEY`: Your Hugging Face API key.
- `HF_API_URL`: URL for the Hugging Face zero-shot classification model.
- `LABELS`: List of predefined categories for classification.

### Functions

- `classify_paper(title, abstract)`: Uses Hugging Face's zero-shot classification model to classify a paper into one of the predefined categories.
- `annotate_papers()`: Annotates the scraped papers using the Hugging Face API and saves the results in JSON format.

### Main Execution

- The script reads the metadata from the `metadata.csv` file.
- For each paper, it combines the title and abstract and sends a request to the Hugging Face API for classification.
- The predicted label is added to the paper's metadata.
- The annotated papers are saved in JSON format.

## Example Output

The annotated papers are saved in a JSON file with the following structure:

```json
[
    {
        "title": "Example Paper Title",
        "url": "https://example.com/paper",
        "year": "2025",
        "abstract": "This is an example abstract.",
        "label": "Deep Learning"
    },
    ...
]
```

## License

This project is licensed under the MIT License. See the LICENSE file for details.

## Acknowledgements

- [Hugging Face](https://huggingface.co/) for providing the zero-shot classification model.
- [NeurIPS](https://neurips.cc/) for providing the paper abstracts and PDFs.

Feel free to contribute to this project by submitting issues or pull requests. Happy annotating!
